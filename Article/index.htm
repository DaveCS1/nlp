<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Comparison of Three Natural Lang</title>
</head>

<body>

<p>Comparison of Three Natural Language Processors, AlchemyAPI, OpenCalais, and 
Semantria</p>
<p><img border="0" src="screenshot-small.png" width="766" height="570"></p>
<h2>Introduction</h2>
<p>I've been looking into Natural Language Processors (NLP's) and thought I 
would share the results of my investigations.&nbsp; We'll look at:</p>
<ul>
	<li>Pricing</li>
	<li>.NET support</li>
	<li>API call examples</li>
	<li>NLP results</li>
</ul>
<p>[TODO: Screenshots of logos]</p>
<p>I've reviewed three NLP providers: AlchemyAPI, OpenCalais, and Semantria.&nbsp; 
They each offer similar services in that they will process text, producing a 
list of entities and relevance of those entities, along with additional 
information that is unique to each of them, which I'll explore briefly as well.&nbsp; I have a particular interest in using NLP's to acquire the semantic content 
from websites (blogs, news feeds, articles, etc.) and began investing three 
NLP's (AlchemyAPI, OpenCalais, and 
Semantria) with regards to price and features.&nbsp; For my particular purposes, 
I was interested in a low-document volume service that was hopefully free for 
limited use and that could provide web page content scraping.&nbsp; As I started 
investigating these three services, it occurred to me that this might be useful 
information for others as well, and thus this article came into being.</p>
<p>With regards to my specific requirements (for a different project) the upshot 
is that only AlchemyAPI and OpenCalais 
provide the price point (free for my small volume requirements) and only AlchemyAPI provides the webpage scraping functionality natively, 
as opposed to using a potentially costly third-party package.&nbsp; That said, 
my requirements are obviously not yours and you should choose a provider 
accordingly.</p>
<h3>What is an NLP?&nbsp; </h3>
<p><i>&quot;Natural language processing (NLP) is a field of computer science, 
artificial intelligence, and linguistics concerned with the interactions between 
computers and human (natural) languages. As such, NLP is related to the area of 
human–computer interaction. Many challenges in NLP involve natural language 
understanding, that is, enabling computers to derive meaning from human or 
natural language input, and others involve natural language generation.&quot; </i>(<a href="http://en.wikipedia.org/wiki/Natural_language_processing">wikipedia</a>)</p>
<h3>Uses for NLP</h3>
<p>Borrowing from another NLP provider, <a href="http://www.smartlogic.com/">
Smartlogic</a>, which I have not reviewed here:</p>
<p><i>&quot;The ability to derive metadata, often in real-time, means that 
information locked-up in content can be made available alongside Big Data flows. 
It is this metadata that will help you turn Big Data into smart data for use in 
decision support.&quot;</i></p>
<p>and...</p>
<p><i>&quot;The resulting metadata drives an array of business-critical tasks 
including:</i></p>
<ul>
	<li><i>Semantic user experience for search</i></li>
	<li><i>Text analytics</i></li>
	<li><i>Workflow processes driven by meaning</i></li>
	<li><i>Regulatory compliance involving unstructured content</i></li>
	<li><i>Automatic classification for Content management</i></li>
	<li><i>Decision support using information locked-up in content</i></li>
	<li><i>Knowledge management</i></li>
	<li><i>Policy application for records management</i></li>
	<li><i>Content visualization</i></li>
	<li><i>Content monetization</i></li>
	<li><i>Improved SEO</i></li>
	<li><i>Text mining&quot;</i></li>
</ul>
<p>I think that says it very well.</p>
<h2>But What Does an NLP Actually Do?</h2>
<p>Each of the three NLP services that I review here parse text and determine 
something called &quot;entities.&quot;&nbsp; While each of the services gives some 
examples of entities, only Semantria provides a clear definition of what an 
entity is: <i>&quot;Semantria’s Named Entity Extraction (NER) feature automatically 
pulls proper nouns from text, such as people, places, companies, brands, job 
titles and more. Each extracted named entity is classified, tagged and assigned 
a sentiment score, which gives meaning and context to each entity.&quot;</i> (<a href="https://semantria.com/features/entity-extraction">https://semantria.com/features/entity-extraction</a>)
</p>
<p>In other words, the primary purpose of an NLP is to extract the nouns, 
determine their types, and provide some &quot;scoring&quot; (relevance or sentiment) of 
the entity within the text.&nbsp; Using relevance, one can supposedly filter out 
entities to those that are most relevant in the document.&nbsp; Using sentiment 
analysis, one can determine the overall sentiment of an entity in the document, 
useful for determining the &quot;tone&quot; of the document with regards to an entity -- 
for example, is the entity &quot;sovereign debt&quot; described negatively, neutrally, or 
positively in the document?</p>
<p>According to the OpenCalais documentation: <i>&quot;Entity relevance scores are 
comparable across input texts. This means that you can use entity relevance 
scores in order to determine entity relevance at a collection level, not just at 
a document level.&quot; </i>(<a href="http://www.opencalais.com/documentation/calais-web-service-api/api-metadata/entity-relevance-score">http://www.opencalais.com/documentation/calais-web-service-api/api-metadata/entity-relevance-score</a>) 
If this meaning can be applied to the other providers, it is a useful value for 
comparing against other documents, but without a definitive meaning of the term 
&quot;relevance&quot;, I'm not sure what the results of such a comparison actually mean.</p>
<h3>Entity Extraction</h3>
<p>Entities are things, often typed, by the NLP, such as people, companies, 
organizations, cities, geographic features, and so forth.&nbsp; In edition to 
the extraction of the entity, each service provides additional information about 
the entity, usually a relevance or sentiment.</p>
<h4>AlchemyAPI Entity</h4>
<p>AlchemyAPI's entity has several attributes:</p>
<ul>
	<li>Type - the type of entity</li>
	<li>Relevance - its relevance (whatever that means) on a scale from 0 to 1</li>
	<li>Count - the number of times the entity occurs in the document</li>
	<li>Text - the entity name</li>
</ul>
<p>There is definitive description of these attributes.&nbsp; Also, sentiment 
analysis is turned off by default, as it incurs an additional transaction count 
against one's daily/monthly allowance.</p>
<p>AlchemyAPI also supports the concept of &quot;linked data&quot;.&nbsp; <i>&quot;Linked Data 
is a method of exposing, sharing, and connecting data on the Web via 
dereferenceable URIs. Linked Data aims to extend the Web with a data commons by 
publishing various open datasets as RDF on the Web and by setting RDF links 
between data items from different data sources. The Linked Data cloud currently 
consists of over 7.4 billion RDF triples, interlinked by 142+ million RDF 
links.&quot; </i>(<a href="http://www.alchemyapi.com/api/linked-data-support/">http://www.alchemyapi.com/api/linked-data-support/</a>.)&nbsp; 
Linked data is partially demonstrated in Concepts (see below) in the 
demonstration program.&nbsp; Currently, Alchemy draws on several linked data 
resources (see the link above as well as <a href="http://linkeddata.org/.">
http://linkeddata.org/</a>.) </p>
<h4>OpenCalais Entity</h4>
<p>An OpenCalais entity has several attributes:</p>
<ul>
	<li>Value - the entity name</li>
	<li>Frequency - possibly the count of occurances, though this conflicts 
	dramatically with AlchemyAPI's &quot;Count&quot;</li>
	<li>Relevance - its relevance (again, whatever that actually means) on a 
	scale from 0 to 1</li>
	<li>Type - the entity type.</li>
</ul>
<p>OpenCalais supports linking entities to DBpedia, Wikipedia, Freebase, 
Reuters.com, GeoNames, Shopping.com, IMDB, LinkedMDB.&nbsp; This feature is not 
demonstrated in the demo code.&nbsp; See also&nbsp;
<a href="http://linkeddata.org/.">http://linkeddata.org/</a>.)</p>
<h4>Semantria's Entity</h4>
<p>Semantria's entity has several attributes (which basically conflicts with the 
documentation on their web page
<a href="https://semantria.com/features/entity-extraction">
https://semantria.com/features/entity-extraction</a>.)</p>
<ul>
	<li>Type</li>
	<li>Evidence</li>
	<li>Confident</li>
	<li>IsAbout</li>
	<li>EntityType</li>
	<li>Title</li>
	<li>Label</li>
	<li>Sentiment Score</li>
	<li>Sentiment Polarity</li>
</ul>
<h3>Other Semantic Information</h3>
<p>In addition, each provides several additional categories of parsing.&nbsp; Be 
aware that the names of these categories and their attributes is derived from 
the API names.</p>
<p><u>AlchemyAPI</u></p>
<ul>
	<li>Keywords - while stating that AlchemyAPI can extract keywords, the 
	actual definition of what &quot;keyword&quot; is lacking.<ul>
		<li>attributes of Keywords are Text and Relevance</li>
	</ul>
	</li>
	<li>Concepts - as with Keywords, there is no definition of what a concept 
	is.<ul>
		<li>attributes of Concepts are Text, Relevance, dbpedia (linked data), 
		freebase (linked data), and opencyc (linked data.)</li>
	</ul>
	</li>
	<li>Relationships - <i>&quot;AlchemyAPI provides the ability to identify named 
	entities within subjects and objects of identified Subject-Action-Object 
	relations, supporting advanced entity recognition capabilities including 
	disambiguation, coreference resolution, and linked data output.&quot;</i> (<a href="http://www.alchemyapi.com/api/relation/entities.html">http://www.alchemyapi.com/api/relation/entities.html</a>)&nbsp; 
	I do not show relationship information in the demo code.</li>
</ul>
<p><u>OpenCalais</u></p>
<ul>
	<li>Topics (aka facts, as is appears on the web pages.)<ul>
		<li>&nbsp;attributes of Topics are Value, Score, and Taxonomy (so far 
		I've only seen &quot;Calais&quot; for taxonomy.)</li>
	</ul>
	</li>
	<li>Events<ul>
		<li>attributes of Events is EventName</li>
	</ul>
	</li>
</ul>
<p><u>Semantria</u></p>
<ul>
	<li>Topics - Themes seem to overall abstractions, such as &quot;Technology&quot;, 
	&quot;Science&quot;, &quot;Hardware&quot;, &quot;Economics&quot;, etc.<ul>
		<li>attributes are Title, Type, Hitcount, StrengthScore, SentimentScore, Label, and 
		SentimentPolarity</li>
	</ul>
	</li>
	<li>Themes - <i>&quot;Semantria extracts themes within your content so that you 
	can determine and follow trends that appear over a period of time. Themes 
	are noun phrases extracted from text and are the primary means of 
	identifying the main ideas within your content. In addition, Semantria 
	assigns a sentiment score to each extracted theme, so you’ll understand the 
	tone behind the themes.&quot;</i> (<a href="https://semantria.com/features/themes">https://semantria.com/features/themes</a>) 
	<ul>
		<li>attributes are Evidence, IsAbout, StrengthScore, SentimentScore, 
		SentimentPolarity, Title</li>
	</ul>
	</li>
</ul>
<h3>Anaphora Resolution</h3>
<p>As pointed out by the folks at OpenCalais, NLP includes something called 
anaphora resolution:</p>
<p><i>&quot;In linguistics, anaphora /&#601;&#712;næf&#601;r&#601;/ is the use of an expression the 
interpretation of which depends upon another expression in context (its 
antecedent or postcedent). In the sentence Sally arrived, but nobody saw her, 
the pronoun her is anaphoric, referring back to Sally. The term anaphora denotes 
the act of referring, whereas the word that actually does the referring is 
sometimes called an anaphor (or cataphor).&quot; </i>(<a href="http://en.wikipedia.org/wiki/Anaphora_(linguistics)">http://en.wikipedia.org/wiki/Anaphora_%28linguistics%29</a>)
</p>
<p>It first puzzled me as to why the counts of entities were often higher than 
the actual instances of those entities, and the above explains the reason why.</p>
<h2>The Three Contenders</h2>
<p>We'll look shortly at what each of the three providers has to say about 
themselves.&nbsp; First however, I'd like to talk a little about document 
processing, web content scraping, and initialization.</p>
<h3>Documents and Web Content Scraping</h3>
<p>All three providers can work with text documents, however only AlchemyAPI 
provides web content scraping directly as part of the API.&nbsp; OpenCalais and Semantria are both document-based 
NLP's and as such require that that the web page scraping has been performed a 
priori.&nbsp; While AlchemyAPI uses its own web page scraping technology,&nbsp; Semantria tightly integrates with
<a href="http://www.diffbot.com/">Diffbot</a> for this service.&nbsp;For the purposes of this demo 
(since DiffBot offers only a 7 day limited free trial), I 
will be using AlchemyAPI's <code>URLGetText</code> API method to provide the 
scraped content for the OpenCalais and Semantria NLP's.</p>
<pre>/// &lt;summary&gt;
/// We use AlchemyAPI to get the page text for OpenCalais and Semantria.
/// &lt;/summary&gt;
protected string GetPageText(string url)
{
  AlchemyWrapper alchemy = new AlchemyWrapper();
  alchemy.Initialize();

  string xml = alchemy.GetUrlText(url);
  XmlDocument xdoc = new XmlDocument();
  xdoc.LoadXml(xml);

  return xdoc.SelectSingleNode(&quot;//text&quot;).InnerText;
}</pre>
<p>This way at least, the text being handed to each NLP will be the same.&nbsp; If you're not processing content from web pages (blogs, news feeds, articles, 
etc.) then this is a moot point with regards to OpenCalais and Semantria.&nbsp; </p>
<h3>Initialization</h3>
<p>Initialization of AlchemyAPI and OpenCalais is very simple.&nbsp; One of the 
issues that you may encounter however is limits to the number of entities (or 
other items) returned.&nbsp; While OpenCalais does not impose any limits, 
AlchemyAPI defaults to 50 entities and Semantria defaults to 5.&nbsp; Changing 
the limit in AlchemyAPI is very simple -- you pass in some additional parameters 
when requesting the processing:</p>
<pre>eparams = new AlchemyAPI_EntityParams();
eparams.setMaxRetrieve(250);</pre>
<p>Semantria is tailored more toward bulk document processing.&nbsp; You can 
have a large number of different configurations that you can choose from 
depending on the document you want processed.&nbsp; Initialization of these 
configurations however takes some time to communicate to the server and the get 
a response back.&nbsp; In the code that I put together, I first request the 
current configurations (there are 8 initially based on language) and then I 
change the limit (which has a maximum of 50) and then this new configuration 
must be uploaded.&nbsp; </p>
<pre>protected void IncreaseLimits()
{
  // This takes considerable time to get the configurations back from the server.
  List&lt;Configuration&gt; configurations = session.GetConfigurations();
  config = configurations.FirstOrDefault(item =&gt; item.Language.Equals(&quot;English&quot;));

  if (config != null)
  {
    config.Document.NamedEntitiesLimit = 50;
    config.Document.ConceptTopicsLimit = 50;
    config.Document.EntityThemesLimit = 50;
    session.UpdateConfigurations(new List&lt;Configuration&gt;() { config });
  }
}</pre>
<p>This all takes time and is why the Process button is disabled for so long 
during application startup.&nbsp; However, once done, the configurations can be 
used without further time penalty.&nbsp; It is also interesting to note that the 
configurations are persisted between sessions -- I assume they are associated 
with your API key, so once configurations are created, technically I don't need 
to run this step unless I want to make a change.&nbsp; For this reason, the 
method IncreaseLimits() in the Initialize method:</p>
<pre>public void Initialize()
{
  string apikey = File.ReadAllText(&quot;semantriaapikey.txt&quot;);
  string[] keys = apikey.Split('\r');
  consumerKey = keys[0].Trim();
  consumerSecret = keys[1].Trim();
  serializer = new JsonSerializer();
  session = Session.CreateSession(consumerKey, consumerSecret, serializer);

  IncreaseLimits();     // &lt;---- Comment me out when the limits have been increased after the first-ever run
}</pre>
<p>can be commented out after you first configure Semantria.</p>
<h3>AlchemyAPI</h3>
<p><img border="0" src="alchemy1.png" width="993" height="206"></p>
<p><a href="http://www.alchemyapi.com/">http://www.alchemyapi.com/</a> </p>
<p><i>&quot;AlchemyAPI is helping pioneer a computer’s ability to understand human 
language and vision. Our web services for real-time text analysis and computer 
vision give you the intelligence needed to transform vast amounts of 
unstructured data into actions that drive your business.&nbsp; Now you can 
easily perform sentiment analysis, keyword extraction, entity extraction, image 
tagging and much more on the massive volumes of web pages, documents, tweets and 
photos produced every second.&quot;</i></p>
<p>One of the unique things about AlchemyAPI that I noticed right away is that 
it performs analysis not just on text but also on images.</p>
<p>AlchemyAPI supports named entity, keyword, and text extraction for content in 
the following eight languages:</p>
<ul>
	<li>English</li>
	<li>French</li>
	<li>German</li>
	<li>Italian</li>
	<li>Portuguese</li>
	<li>Russian</li>
	<li>Spanish</li>
	<li>Swedish</li>
</ul>
<p>Content sentiment analysis currently supports English and German, with 
support for additional languages in development.</p>
<p>To avoid biasing the timing results, I first request the page text using 
AlchemyAPI and then feed this text into all three NLP's.&nbsp; It should be 
noted that this produces worse timing for AlchemyAPI than if I had provided the 
web page URL directly -- meaning that if you give AlchemyAPI the URL, it 
performs better, and in many cases, significantly better than the other two. 
It's unfortunate that I have to dumb-down AlchemyAPI to equalize the timing 
tests with the other two NLP providers.</p>
<h3>OpenCalais</h3>
<p><img border="0" src="opencalais1.png" width="988" height="202"></p>
<p><a href="http://www.opencalais.com/">http://www.opencalais.com/</a> </p>
<p><i>&quot;We want to make all the world's content more accessible, interoperable 
and valuable. Some call it Web 2.0, Web 3.0, the Semantic Web or the Giant 
Global Graph - we call our piece of it Calais.&nbsp; Calais is a rapidly growing 
toolkit of capabilities that allow you to readily incorporate state-of-the-art 
semantic functionality within your blog, content management system, website or 
application.&quot;</i></p>
<p>OpenCalais supports English, French and Spanish.</p>
<h3>Semantria</h3>
<p><img border="0" src="semantria1.png" width="962" height="191"></p>
<p><a href="https://semantria.com/">https://semantria.com/</a> </p>
<p><i>&quot;Semantria applies Text and Sentiment Analysis to tweets, facebook posts, 
surveys, reviews or enterprise content.&nbsp; Semantria is a complete 
cloud-based text and sentiment analysis solution launched in 2011.&nbsp; Faster 
than a human (60,000x), more accurate than 2 humans (80% of the time it's flat 
out smarter), and living in the Amazon cloud, Semantria extracts the meaning, 
tone, and so much more from any text it’s given.&quot;</i></p>
<p>One of the interesting things about Semantria is the Excel plugin: <i>&quot;Semantria 
is the only Text and Sentiment Analysis solution for Excel.&nbsp; It turns it 
into a powerful and easy-to-use tool for monitoring and visualizing Twitter, 
Facebook, surveys and other unstructured data.&quot;</i></p>
<p>Also, Semantria supports these languages:</p>
<ul>
	<li>English (US/UK)</li>
	<li>French (FR/CA)</li>
	<li>Spanish</li>
	<li>Portuguese</li>
	<li>Italian</li>
	<li>German</li>
	<li>Mandarin (Traditional and Simplified)</li>
	<li>Korean</li>
	<li>Japanese (beta)</li>
	<li>Malay (Bahasa Melayu)</li>
	<li>Indonesian (Bahasa Indonesia)</li>
	<li>Singlish (Singapore Colloquial Language)</li>
</ul>
<p>Also, Semantria integrates tightly with <a href="http://www.diffbot.com/">
Diffbot</a> for webpage scraping.</p>
<h2>Pricing</h2>
<p>Pricing varies considerably and is based on number of transactions being 
processed daily/monthly and level of customer support.</p>
<h3>AlchemyAPI</h3>
<p>The pricing that I describe here may not be up on the AlchemyAPI website at 
the time of this writing, as I was notified that the pricing structure has 
changed somewhat.</p>
<p>There are five tiers:</p>
<ol>
	<li>Free: 1,000 transactions / day, supporting five concurrent requests, no 
support</li>
	<li>$250/month: 90,000 transactions / month, 5 concurrent requests, email support</li>
	<li>$750/month: 300,000 transactions / month, 15 concurrent requests, email 
support</li>
	<li>$1750/month: 3,000,000 transactions / month, 25 concurrent requests, email 
and phone support, uptime guarantee</li>
	<li>Custom for more than 3M transactions.</li>
</ol>
<p>For academia, AlchemyAPI offers an increased number of transactions per day 
in the Free tier.</p>
<p>There is also a &quot;Performance and Support Package&quot; that you can select:</p>
<ul>
	<li>Free</li>
	<li>Pro plan - $595 / mo</li>
	<li>Enterprise plan - $1995 / mo</li>
</ul>
<p>As well as a month-to-month subscription option:</p>
<ul>
	<li>First 250,000 transactions / mo: $0.0035 / transaction</li>
	<li>Next 750,000 transactions /mo: $0.0015 / transaction</li>
	<li>Next 1,000,000 transactions /mo: $0.00075 / transaction</li>
	<li>Next 3,000,000 transactions /mo: $0.00050 / transaction</li>
	<li>Anything over 5,000,000 transactions / mo: $0.0035 / transaction</li>
</ul>
<h3>OpenCalais</h3>
<p>Free: 50,000 transactions per license per day and four transactions per 
second</p>
<p>Commercial License: <i>&quot;Our commercial services provide the same 
functionality as OpenCalais but with a production-strength twist. The service 
provides a high-performance SLA, a daily transaction limit of 100,000 
transactions and an enhanced 20 transactions per second rate. Additional volume 
blocks up to maximum of 2,000,000 transactions per day are available. 
ProfessionalCalais meets needs unique to larger-scale publishers. 
ProfessionalCalais is available as an annual contract.&quot;</i></p>
<h3>Semantria</h3>
<p>There are five tiers:</p>
<ol>
	<li>Free Trial: First 10,000 transactions (total, not per month) free, full 
featured (although see below in the API discussion for issues that I 
encountered)</li>
	<li>$999/month: Excel Seat, unlimited transactions</li>
	<li>$999/month: API Standard, 100,000 transactions / month, some limits (like 
number of supported languages)</li>
	<li>$1999/month: API Premium, 1,000,000 transactions / month</li>
	<li>Custom for more than 1M transactions per month</li>
</ol>
<p>DiffBbot, which integrates with Semantria for webpage scraping, has its own 
pricing structure and I am not aware of how that changes the pricing structure. </p>
<h2>API's</h2>
<p>Each provider requires that you obtain a product key to interface with the 
API, which is a simple process.&nbsp; I have not included my keys, so to run the 
code, you will need to register with each provider to obtain your own API key and place it into the 
appropriate text file (see the code for filenames.)&nbsp; Because I'm working in 
C# / .NET, I obtained a .NET library to handle the SOAP/REST calls, either from 
the provider directly or one that I was referred to by the provider.&nbsp; All 
API's provided examples and various degrees of unit tests.</p>
<h3>AlchemyAPI</h3>
<p>The AlchemyAPI, to put it simply, just worked.&nbsp; It provided the 
functionality that I was looking for (give it a URL and it returns semantic 
results) and it worked without any issues, which is something I cannot say for 
OpenCalais or Semantria.&nbsp; Interfacing with the .NET API that they provide 
is quite simple, for example:</p>
<pre>protected AlchemyAPI.AlchemyAPI alchemyObj;

public void Initialize()
{
  alchemyObj = new AlchemyAPI.AlchemyAPI();
  alchemyObj.LoadAPIKey(&quot;alchemyapikey.txt&quot;);
}

public string GetUrlText(string url)
{
  return alchemyObj.URLGetText(url);
}

public DataSet LoadEntitiesFromUrl(string url)
{
  DataSet dsEntities = new DataSet();
  string xml = alchemyObj.URLGetRankedNamedEntities(url);
  TextReader tr = new StringReader(xml);
  XmlReader xr = XmlReader.Create(tr);
  dsEntities.ReadXml(xr);
  xr.Close();
  tr.Close();

  return dsEntities;
}</pre>
<p>Unlike OpenCalais and Semantra, I had no issues interfacing with the .NET API 
library &quot;out of the box.&quot;</p>
<p>Also, unlike OpenCalais and Semantra, AlchemyAPI returns an XML document 
rather than data mapped to library classes.</p>
<h3>OpenCalais</h3>
<p>The <a href="http://opencalais.codeplex.com/">Open Calais .NET library</a> on 
Codeplex was the most difficult of the three libraries to work with, requiring me to fix 
the entity enumerator.&nbsp; The first issue with this library is that, when you 
unzip it, all the files are read-only.&nbsp; This made it impossible to load 
the projects and solutions into VS2012 without first changing all the files and 
folders to read-write.</p>
<p>Second, using their sample document, I was getting 
&quot;Unhandled Exception: System.ArgumentException: Requested value 'PoliticalEvent' 
was not found.&quot; because there were missing types in the <code>CalaisSimpleEntityType</code> 
enumerator:</p>
<pre>// Ignore topics and events are they are processed seperately
if (elementName != &quot;Topics&quot; &amp;&amp; elementName != &quot;Event&quot; &amp;&amp; elementName != &quot;Topic&quot;)
{
  newSimpleEntity.Type = (CalaisSimpleEntityType)Enum.Parse(typeof(CalaisSimpleEntityType), result.Name.ToString());
  yield return newSimpleEntity;
}</pre>

<p>To fix this, I had to go in and change this class:</p>
<pre>public class CalaisSimpleEntity
{
  public string Value { get; set; }
  public int Frequency { get; set; }
  public string Relevance { get; set; }
  public CalaisSimpleEntityType Type { get; set; }
}</pre>
<p>so that Type was a string (why it's mapped to an enumeration is beyond me):</p>
<pre>public class CalaisSimpleEntity
{
  public string Value { get; set; }
  public int Frequency { get; set; }
  public string Relevance { get; set; }
  public string Type { get; set; }
}</pre>
<p>and the offending line of code:</p>
<pre>newSimpleEntity.Type = result.Name.ToString();</pre>
<p>I also had to fix a unit test that failed to compile as the result of the 
type change.</p>
<p>I also found it annoying that the properties for Entities, Topics, and Events are 
IEnumerable's, meaning you have to explicitly iterate through the collection to 
acquire the contents, which, underlying, involves some processing of the XML document.&nbsp; This 
is very inefficient, especially if the collection is iterated over many times by 
different functions, 
but can be worked around by converting the collections to lists, as I did in the 
simple &quot;get&quot; functions, for example:</p>
<pre>return document.Entities.ToList();</pre>
<p>Given that the contents of these collections is unchanging, I see no reason 
not to pre-populate the collections with their items.</p>
<p>My other significant issue with OpenCalais is that my sample document (the 
text of Wikipedia's page on Computer Science) resulted in a &quot;content is not 
valid&quot; exception from the server.&nbsp; It turns out that the offending sentence 
is this:</p>
<p><i>The term is used mainly in the Scandinavian countries. Also, in the early 
days of computing, a number of terms for the practitioners of the field of 
computing were suggested in the Communications of the ACM – turingineer, 
turologist, flow-charts-man, applied meta-mathematician, and applied 
epistemologist.[34] </i><br>
<br>
and can be further reduced to the use of the &quot;–&quot; character -- the Unicode 
character 0x2013 &quot;EN DASH&quot;.&nbsp; OpenCalais is apparently rather sensitive, but 
we can strip Unicode:</p>
<pre>// A couple options: http://stackoverflow.com/questions/123336/how-can-you-strip-non-ascii-characters-from-a-string-in-c
string asAscii = Encoding.ASCII.GetString(
  Encoding.Convert(
    Encoding.UTF8,
    Encoding.GetEncoding(
        Encoding.ASCII.EncodingName,
        new EncoderReplacementFallback(string.Empty),
        new DecoderExceptionFallback()
    ),
    Encoding.UTF8.GetBytes(content)
  )
); </pre>
<p>Once properly sanitized, the actual call to parse the document and extract 
data is very simple:</p>
<pre>CalaisDotNet calais = new CalaisDotNet(apikey, asAscii);
document = calais.Call&lt;CalaisSimpleDocument&gt;();

...

public IList GetEntities()
{
  return document.Entities.ToList();
}</pre>
<h4>Other Tidbits Regarding OpenCalais</h4>
<p>There is a complementary service, <a href="http://semanticproxy.com/">
http://semanticproxy.com/</a>, that is supposed to perform content scraping, 
however, when I tried to use it (at different times) I constantly received a 
&quot;Java out of memory&quot; error.</p>
<p>In this demonstration code, I am using &quot;Simple Format&quot; output.&nbsp; 
According to Ofer Harari:</p>
<p><i>&quot;Simple Format output which is the poorest format in terms of capabilities 
(Simple format is for a quick and easy output from Calais. Not for a detailed 
response). The standard format is RDF or JSON. These outputs include all the 
metadata that Open Calais can extract.&quot;</i></p>
<h3>Semantria</h3>
<p>For some reason I found Semantria's .NET API to be complicated to work with, 
which I realized after having success with it is that it takes a different 
approach to processing documents.&nbsp; With AlchemyAPI and OpenCalais, you make 
the call and wait for the results.&nbsp; With Semantria, it is very bulk-process 
centric.&nbsp; Documents that are sent to the Semantria servers are queued and 
can return asynchronously with results or in a different order from the original 
input into the queue.&nbsp; This makes working with a single document more 
complex (see code below) but clearly, the strength of Semantria's API is much 
more evident when working with bulk documents. </p>
<p>There is also two modes of document analysis, described here:
<a href="https://semantria.com/support/developer/overview/processing">
https://semantria.com/support/developer/overview/processing</a> </p>
<ol>
	<li>Detailed Mode</li>
	<li>Discovery Mode</li>
</ol>
<h4>Detailed Mode</h4>
<p><i>&quot;After submitting documents to be queued, each document will be analyzed 
independently of the others. Semantria API will return an analysis for each 
document.&quot;</i></p>
<h4>Discovery Mode</h4>
<p><i>&quot;This method submits an array of documents to be analyzed in relation to 
each other and returns one output. Discovery analysis will contain a summary of 
commonalities, sentiments, named entity extraction, themes, and categorization 
for all the documents in the collection.&quot;</i></p>
<p>This article reviews Detailed Mode only, however, when working with Discovery 
Mode I &quot;discovered&quot; an issue with document size--with my scraped 
webpage content string, I was getting 
&quot;line too long&quot; exceptions.</p>
<p>Calling the parser requires polling to see if the document is analyzed.&nbsp; 
While there is a DocsAutoResponse event callback, this isn't what it seems -- if 
the document is queued (which is the standard behavior) this callback is never 
made, and I'm not sure how this event helps, unless it is associated with the 
bulk processing.&nbsp; Here is the parse request and response poll code:</p>
<pre>public void ParseUrl(string content)
{
  string docId = Guid.NewGuid().ToString();
  Document doc = new Document() {Id = docId, Text = content};
  docResults = new List&lt;DocAnalyticData&gt;();
  int result = session.QueueDocument(doc, configID);
  DocAnalyticData ret;
  DateTime start = DateTime.Now;

  do
  {
    // Semantria guarantees a result within 10 seconds. But how fast is it really?
    Thread.Sleep(100);
    ret = session.GetDocument(doc.Id, configID);

    if ((DateTime.Now - start).TotalSeconds &gt; 15)
    {
        throw new ApplicationException(&quot;Semantria did not return with 15 seconds.&quot;);
    }
  } while (ret.Status == Semantria.Com.TaskStatus.QUEUED);

  if (ret.Status == Semantria.Com.TaskStatus.PROCESSED)
  {
    docResults.Add(ret);
  }
  else
  {
    throw new ApplicationException(&quot;Error processing document: &quot; + ret.Status.ToString());
  }
}</pre>
<p>As stated at the beginning of this article under Initialization, the default 
number of entities is 5 (themes is also 5 and topics is 10).&nbsp; In this 
article I have increased the limit to 50 (though there was some confusion as to 
whether the absolute limit was 20, as one can see from running the program, that 
is not the case.)</p>
<h2>A Sample Run</h2>
<p>The screenshots that I've been using come from parsing this page:
<a href="http://en.wikipedia.org/wiki/Computer_science">
http://en.wikipedia.org/wiki/Computer_science</a>.&nbsp; You can of course enter 
your own URL in the demo application (try a Code Project article, the results 
are often interesting.)&nbsp; The code that does the processing runs each 
service request asynchronously, marshalling the UI data grid updates back onto 
the UI thread (not shown).&nbsp; I also cache (using the URL's hash code) the 
scraped web page returned by AlchemyAPI so I'm not constantly making a &quot;get page 
content&quot; request to AlchemyAPI when testing the same web pages over and over.</p>
<pre>/// &lt;summary&gt;
/// Process the URL with AlchemyAPI, OpenCalais, and Semantra NLP's.
/// &lt;/summary&gt;
protected async void Process(object sender, EventArgs args)
{
  btnProcess.Enabled = false;
  ClearAllGrids();
  string url = tbUrl.Text;
  sbStatus.Text = &quot;Acquiring page content...&quot;;

  // Eases debugging when we comment out one or more of the NLP's to test the other.
  double alchemyTime = 0;
  double calaisTime = 0;
  double semantriaTime = 0;

  string pageText = await Task.Run(() =&gt; GetUrlText(url));

  sbStatus.Text = &quot;Processing results with Alchemy...&quot;;

  double alchemyTime = await Task.Run(() =&gt;
  {
    LoadAlchemyResults(pageText);
    return ElapsedTime();
  });

  sbStatus.Text = &quot;Processing results with OpenCalais...&quot;;

  double calaisTime = await Task.Run(() =&gt;
  {
    LoadCalaisResults(pageText);
    return ElapsedTime();
  });

  sbStatus.Text = &quot;Processing results with Semantria...&quot;;

  double semantriaTime = await Task.Run(() =&gt;
  {
    LoadSemantriaResults(pageText);
    return ElapsedTime();
  });
  
  sbStatus.Text = &quot;Done processing.&quot;;

  ReportTimes(alchemyTime, calaisTime, semantriaTime);
  btnProcess.Enabled = true;
}</pre>
<p>This way, the UI remains responsive and you can interact with it while other 
results are still coming in.</p>
<h2>Conclusions</h2>
<p>The testing here is not exhaustive--some may argue not even comprehensive.&nbsp; 
I am not testing high throughputs.&nbsp; I also haven't simulated customer service 
issues.&nbsp; All three providers replied very quickly when I emailed them that 
I was writing this article, and I've had excellent and helpful conversations 
with all of them.</p>
<p>Also, as a general criticism, each provider would do well to explicitly 
define what the various terms mean in their API's and the collection attributes.&nbsp; 
If one is to use these services for serious analysis of documents, an exact 
meaning is a requirement.</p>
<p>While I had originally set out with the goal of not drawing any conclusions 
about the three providers and rather to simply present my findings, I have 
definitely become biased towards AlchemyAPI based on price and features.&nbsp; 
It is ironic that I'm using AlchemyAPI's web page content extraction to feed the 
scraped page text into OpenCalais and Semantria.&nbsp; On the other hand, 
Semantria returns some interesting attributes (many of which I will admit I 
don't fully understand) that could be useful inputs to further analysis, 
categorization, and meaning extraction.&nbsp; If only it supported a free 
version for us poor folk with limited analysis requirements, but that's a 
personal bias.</p>
<p>Lastly, I feel as though I owe an apology to the reader -- this review has 
taken a considerable amount of time and I have glossed over (or outright 
skipped) many of the features of these providers.&nbsp; While this article 
hopefully provides some useful information, I strongly suggest that you invest 
each provider in detail yourself to see what additional features and 
capabilities exist.</p>

</body>

</html>